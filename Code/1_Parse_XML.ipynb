{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as et\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing Module\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check core count\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040337\n"
     ]
    }
   ],
   "source": [
    "# Import updated data\n",
    "filePath='/home/ec2-user/SageMaker/data/RegNews-Jan1985Dec2021/'\n",
    "files=[]\n",
    "for file in os.listdir(filePath):\n",
    "    files.append(file)\n",
    "print(len(files))\n",
    "#print(files[0:5])\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.xml'):\n",
    "        pass\n",
    "    else:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853284\n"
     ]
    }
   ],
   "source": [
    "# Clean archived datasets to free up some storage\n",
    "# filePath_old='/home/ec2-user/SageMaker/data/corpus/'\n",
    "# files=[]\n",
    "# for file in os.listdir(filePath_old):\n",
    "#     files.append(file)\n",
    "print(len(files))\n",
    "# for f in os.listdir(filePath_old):\n",
    "#     os.remove(os.path.join(filePath_old, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print one XML example\n",
    "def print_xml(file):\n",
    "    tree = etree.parse(file)\n",
    "    xml = etree.tostring(tree, encoding=\"unicode\", pretty_print=True)\n",
    "    print(xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RECORD>\n",
      "   <GOID>426572138</GOID>\n",
      "   \n",
      "   <Obj>\n",
      "      <SourceRollupType>Newspapers</SourceRollupType>\n",
      "      <ObjectTypes>\n",
      "         <other ObjectTypeOrigin=\"Publication\">NEWSPAPER</other>\n",
      "         <mstar>News</mstar>\n",
      "      </ObjectTypes>\n",
      "      <ObjectRollupType>Articles - All Types</ObjectRollupType>\n",
      "      <TitleAtt>\n",
      "         <Title>Town Is Split Over Ending 129-Year Era</Title>\n",
      "      </TitleAtt>\n",
      "      <NumericDate>1987-08-08</NumericDate>\n",
      "      <StartDate>1987-08-08</StartDate>\n",
      "      <EndDate>1987-08-08</EndDate>\n",
      "      <AlphaDate>Aug 8, 1987</AlphaDate>\n",
      "      <Language>       \n",
      "         <RawLang>English</RawLang>\n",
      "     </Language>\n",
      "      <Language IsPrimary=\"true\">       \n",
      "         <ISO>         \n",
      "            <ISOCode>ENG</ISOCode>\n",
      "            <ISOExpansion ISOCode=\"ENG\">English</ISOExpansion>\n",
      "         </ISO>\n",
      "     </Language>\n",
      "      <Copyright>\n",
      "         <CopyrightData>Copyright New York Times Company Aug 8, 1987</CopyrightData>\n",
      "      </Copyright>\n",
      "      <PrintLocation>       \n",
      "         <StartPage>1.29</StartPage>\n",
      "         <Pagination>1.29</Pagination>\n",
      "         <DocSection>1</DocSection>\n",
      "         <DocSubSection>Section 1; Page 29, Column 2; Metropolitan Desk</DocSubSection>\n",
      "         <ColumnNumber>2</ColumnNumber>\n",
      "     </PrintLocation>\n",
      "      <ObjectIDs>       \n",
      "         <ObjectID IDOrigin=\"PQ\">\n",
      "            <DOCID>956992531</DOCID>\n",
      "         </ObjectID>\n",
      "         <ObjectID IDOrigin=\"PQ\">\n",
      "            <PCID>17040171</PCID>\n",
      "         </ObjectID>\n",
      "         <ObjectID IDOrigin=\"PQ\">\n",
      "            <PMID>7818</PMID>\n",
      "         </ObjectID>\n",
      "         <ObjectID>\n",
      "            <CODEN>NYTIAO</CODEN>\n",
      "         </ObjectID>\n",
      "         <ObjectID>\n",
      "            <ProvJournalCode>NYT</ProvJournalCode>\n",
      "         </ObjectID>\n",
      "         <ObjectID IDOrigin=\"NYT\">\n",
      "            <PublisherXID>217887-19870808</PublisherXID>\n",
      "         </ObjectID>\n",
      "     </ObjectIDs>\n",
      "      <LexileScore>1440</LexileScore>\n",
      "      <DateLine>CANAAN, Conn., Aug. 7</DateLine>\n",
      "      <Desk>Metropolitan Desk</Desk>\n",
      "      <Contributors>       \n",
      "         <Contributor ContribOrder=\"1\">\n",
      "            <Author>\n",
      "               <DisplayForm>RICHARD L. MADDEN, Special to the New York Times</DisplayForm>\n",
      "               <OriginalFormAtt ContribOrigin=\"pqauth\">\n",
      "                  <OriginalForm>RICHARD L. MADDEN, Special to the New York Times</OriginalForm>\n",
      "               </OriginalFormAtt>\n",
      "            </Author>\n",
      "         </Contributor>\n",
      "     </Contributors>\n",
      "      <Terms>       \n",
      "         <GenSubjTerm TermSource=\"EXT\" PndxHeader=\"true\">\n",
      "            <GenSubjValue>ZONING</GenSubjValue>\n",
      "         </GenSubjTerm>\n",
      "         <GenSubjTerm TermSource=\"EXT\" PndxHeader=\"true\">\n",
      "            <GenSubjValue>LOCAL GOVERNMENT</GenSubjValue>\n",
      "         </GenSubjTerm>\n",
      "         <GenSubjTerm TermSource=\"EXT\" PndxHeader=\"true\">\n",
      "            <GenSubjValue>LAW AND LEGISLATION</GenSubjValue>\n",
      "         </GenSubjTerm>\n",
      "         <Term TermSource=\"EXT\" PndxHeader=\"true\">\n",
      "            <Geographic>NORTH CANAAN (CONN)</Geographic>\n",
      "         </Term>\n",
      "         <Term TermSource=\"EXT\" PndxHeader=\"true\">\n",
      "            <Geographic>CANAAN (CONN)</Geographic>\n",
      "         </Term>\n",
      "         <Term TermSource=\"ABI\" PndxHeader=\"true\">\n",
      "            <Personal>Pozzetta, Henry H</Personal>\n",
      "         </Term>\n",
      "         <Term TermSource=\"ABI\" PndxHeader=\"true\">\n",
      "            <Personal>Festa, Roger</Personal>\n",
      "         </Term>\n",
      "         <Term TermSource=\"EXT\" PndxHeader=\"true\">\n",
      "            <Personal>MADDEN, RICHARD L</Personal>\n",
      "         </Term>\n",
      "     </Terms>\n",
      "      <Abstract>\n",
      "         <Short WordCount=\"123\">\n",
      "            <AbsText HTMLContent=\"true\">          &lt;html&gt;            &lt;head&gt;              &lt;meta name=\"ValidationSchema\" content=\"http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd\"/&gt;              &lt;title/&gt;            &lt;/head&gt;            &lt;body&gt;              &lt;p&gt;With zoning, ''you're going to have a commission to tell you what to do with your property, how much acreage you must have,'' said Frank Zucco, a former selectman who has built several buildings in town, ''We're going to be stuck with what we don't want.''&lt;/p&gt;              &lt;p&gt;''The town is being developed, whether we like it or not,'' said a supporter of zoning, Bob Angus, a writer. ''As much as I'd like to keep it as it is, I'm afraid that's not an option.''&lt;/p&gt;              &lt;p&gt;The town considered a proposed zoning code in 1972, but rejected it. ''Zoning has been kept in a closet a long, long time,'' Mr. [Henry H. Pozzetta] said in an interview. ''Politically, an individual wouldn't dare even discussing zoning.''&lt;/p&gt;            &lt;/body&gt;          &lt;/html&gt;</AbsText>\n",
      "         </Short>\n",
      "      </Abstract>\n",
      "   </Obj>\n",
      "   <TextInfo>       \n",
      "      <Text WordCount=\"870\" HTMLContent=\"true\">&lt;html&gt;            &lt;head&gt;              &lt;meta name=\"ValidationSchema\" content=\"http://www.w3.org/2002/08/xhtml/xhtml1-strict.xsd\"/&gt;              &lt;title/&gt;            &lt;/head&gt;            &lt;body&gt;              &lt;p&gt;LEAD: As developers creep toward them through the picturesque Litchfield Hills, residents of this old commercial and farming town on the Massachusetts border are waging a spirited debate over whether to end a 129-year tradition of unfettered building.  &lt;/p&gt;              &lt;p&gt;As developers creep toward them through the picturesque Litchfield Hills, residents of this old commercial and farming town on the Massachusetts border are waging a spirited debate over whether to end a 129-year tradition of unfettered building.&lt;/p&gt;              &lt;p&gt;Across the country, local officials are debating the import of recent Supreme Court decisions strengthening the rights of property owners when zoning restricts the reasonable use of their land. But here the issue is much more basic. The town of North Canaan - Canaan is its principal village - has never had zoning laws.&lt;/p&gt;              &lt;p&gt;In a prelude to a referendum Aug. 18 that will decide the issue, more than 60 people crowded into a small annex at Town Hall here this week to argue about whether North Canaan needs zoning. They were clearly divided.&lt;/p&gt;              &lt;p&gt;With zoning, ''you're going to have a commission to tell you what to do with your property, how much acreage you must have,'' said Frank Zucco, a former selectman who has built several buildings in town, ''We're going to be stuck with what we don't want.''&lt;/p&gt;              &lt;p&gt;''The town is being developed, whether we like it or not,'' said a supporter of zoning, Bob Angus, a writer. ''As much as I'd like to keep it as it is, I'm afraid that's not an option.''&lt;/p&gt;              &lt;p&gt;Only seven of Connecticut's 169 cities and towns do not have zoning laws -Bethlehem, Eastford, Goshen, North Canaan, Pomfret, Sterling and Woodstock. All seven are small - Woodstock, with 5,260 people, is the largest. Most are off the beaten track.  More and More Debates But with real-estate prices rising and residential development increasing, particularly in the small towns in northwestern Connecticut, debates about zoning are increasing.&lt;/p&gt;              &lt;p&gt;At least three other Litchfield County towns - Winsted, Litchfield and Harwinton - have imposed moratoriums on development. On July 21, Goshen, about 10 miles south of North Canaan, rejected a proposal to adopt zoning by three votes, 322 to 319.&lt;/p&gt;              &lt;p&gt;Despite the vote, some Goshen residents said the debate would not end. ''Heck no,'' said the First Selectman, Richard C. Kobylenski. ''When developers keep pushing, the issue never goes away.''&lt;/p&gt;              &lt;p&gt;North Canaan, incorporated in 1858, covers 19.6 square miles and has a population of 4,300. It was once a thriving railroad junction with limestone quarries and iron smelters. Now, its factories turn out such products as medical and electronic equipment. Commercial and industrial buildings account for more than half of the tax base.&lt;/p&gt;              &lt;p&gt;Along the main roads, Routes 7 and 44, working dairy farms and cornfields are not far from the factories. In Canaan, where the two highways intersect, stately Victorian houses mix with modest bungalows and an occasional two-story apartment building. A Restored Depot &lt;/p&gt;              &lt;p&gt;Along the main business stretch, some of the old commercial buildings, have been refurbished and the railroad depot, built in 1872, has been restored for weekend excursion trains down the Housatonic Valley.&lt;/p&gt;              &lt;p&gt;Down the street from the depot, next to St. Joseph's Roman Catholic Church, is a McDonald's restaurant, whose arrival two years ago, some residents say, helped kindle the current debate.&lt;/p&gt;              &lt;p&gt;''This is still a workingman's town,'' said Henry H. Pozzetta, the First Selectman for the last six years. Although North Canaan has not become a fashionable country retreat for New Yorkers - like some of its neighboring towns - real estate prices are rising, he said.&lt;/p&gt;              &lt;p&gt;''A year ago, people could still buy a house here for less than $100,000,'' he said. ''You can't do that today. When we see the growth to the south of us, it should make us aware of what the possibility is. We need some type of controlled growth.''&lt;/p&gt;              &lt;p&gt;Without zoning, anything can be built as long as it meets state building and sanitary codes, Mr. Pozzetta said. ''We've been fortunate so far,'' he said, ''but I feel someone is going to take advantage of us.''&lt;/p&gt;              &lt;p&gt;The town considered a proposed zoning code in 1972, but rejected it. ''Zoning has been kept in a closet a long, long time,'' Mr. Pozzetta said in an interview. ''Politically, an individual wouldn't dare even discussing zoning.''&lt;/p&gt;              &lt;p&gt;Mr. Pozzetta, a Republican, is not seeking re-election this fall, but he said that was not the main reason he decided to raise the issue. ''I felt it was time to bring it out into the open and give the people an opportunity to vote,'' he said.&lt;/p&gt;              &lt;p&gt;At Town Meeting this week, supporters of zoning said they favored basic rules that would, for example, designate specific areas of town for industrial development and establish minimum sizes for lots, rather than detailed regulations that would govern architecture or color schemes. But other residents complained that altering regulations would be difficult.&lt;/p&gt;              &lt;p&gt;One, Roger Festa, said a zoning commission would be ''the judges and the jury'' on what could be built.&lt;/p&gt;              &lt;p&gt;''There's a very strong feeling here that they want more time,'' Mr. Festa said of his neighbors.&lt;/p&gt;              &lt;p&gt;''The clock has started, Roger,'' Mr. Pozzetta replied.  &lt;/p&gt;            &lt;/body&gt;          &lt;/html&gt;</Text>\n",
      "     </TextInfo>\n",
      "   <DFS>\n",
      "      <PubFrosting>\n",
      "         <Title>New York Times</Title>\n",
      "         <MpubId>11561</MpubId>\n",
      "         <SortTitle>New York Times</SortTitle>\n",
      "         <Qualifier>New York, N.Y.</Qualifier>\n",
      "         <Edition>Late Edition (East Coast)</Edition>\n",
      "         <JournalCode>NYT</JournalCode>\n",
      "         <SourceType>Newspapers</SourceType>\n",
      "         <StartDate>18570101</StartDate>\n",
      "         <EndDate>99991231</EndDate>\n",
      "         <publisher>\n",
      "            <PublisherName>New York Times Company</PublisherName>\n",
      "            <PublisherAddress>\n",
      "               <Address1>620 8th Ave</Address1>\n",
      "               <City>NEW YORK</City>\n",
      "               <Province>NY</Province>\n",
      "               <ZipCode>10018</ZipCode>\n",
      "               <Country>United States</Country>\n",
      "            </PublisherAddress>\n",
      "            <URL>http://www.nytimes.com/</URL>\n",
      "         </publisher>\n",
      "         <Locators>\n",
      "            <Locator Type=\"PQPMID\">\n",
      "               <Name>7818</Name>\n",
      "            </Locator>\n",
      "            <Locator Type=\"ISSN\">\n",
      "               <Name>03624331</Name>\n",
      "            </Locator>\n",
      "            <Locator Type=\"CODEN\">\n",
      "               <Name>NYTIAO</Name>\n",
      "            </Locator>\n",
      "         </Locators>\n",
      "         <CatalogNum>60001.00</CatalogNum>\n",
      "         <Languages>\n",
      "            <Language>eng</Language>\n",
      "         </Languages>\n",
      "         <Flags>\n",
      "            <Flag Type=\"BLOCK_BY_PUB\">N</Flag>\n",
      "            <Flag Type=\"ARTICLE_TRANSLATION\">Y</Flag>\n",
      "            <Flag Type=\"ALERTING_FLAG\">Y</Flag>\n",
      "            <Flag Type=\"DOC_USAGE_ROYALTIES\">N</Flag>\n",
      "            <Flag Type=\"UNSTRUCTURED_DATA\">N</Flag>\n",
      "            <Flag Type=\"PRIMARY_SOURCE_FLAG\">N</Flag>\n",
      "            <Flag Type=\"LION_CONTENT_TYPE\">Reviews</Flag>\n",
      "            <Flag Type=\"OPEN_LAYER_RIGHTS\">OL_IN_NONE</Flag>\n",
      "            <Flag Type=\"OL_CRAWL_BLOCKED\">Y</Flag>\n",
      "            <Flag Type=\"EXCLUDE_FROM_TDM\">N</Flag>\n",
      "            <Flag Type=\"EXCLUDE_FROM_GOOGLE_SCHOLAR\">N</Flag>\n",
      "            <Flag Type=\"INCLUDE_IN_PAC\">N</Flag>\n",
      "         </Flags>\n",
      "         <Subjects>\n",
      "            <Subject>General Interest Periodicals--United States</Subject>\n",
      "         </Subjects>\n",
      "         <CurrentTitle>\n",
      "            <Title>New York Times</Title>\n",
      "            <SortTitle>New York Times</SortTitle>\n",
      "            <Qualifier>New York, N.Y.</Qualifier>\n",
      "            <EndIssueDate>99991231</EndIssueDate>\n",
      "            <Edition>Late Edition (East Coast)</Edition>\n",
      "            <Locators>\n",
      "               <Locator Type=\"PQPMID\">\n",
      "                  <Name>7818</Name>\n",
      "               </Locator>\n",
      "               <Locator Type=\"ISSN\">\n",
      "                  <Name>03624331</Name>\n",
      "               </Locator>\n",
      "               <Locator Type=\"CODEN\">\n",
      "                  <Name>NYTIAO</Name>\n",
      "               </Locator>\n",
      "            </Locators>\n",
      "            <CatalogNum>60001.00</CatalogNum>\n",
      "         </CurrentTitle>\n",
      "         \n",
      "         <CoverImageType>None</CoverImageType>\n",
      "         <BrowseType>IssueDateBrowse</BrowseType>\n",
      "         <EmbargoDays>0</EmbargoDays>\n",
      "         <HasGaps>1</HasGaps>\n",
      "         <CoverageRange>\n",
      "            <AlphaStartDate>Jun 1, 1980</AlphaStartDate>\n",
      "            <AlphaEndDate>Current</AlphaEndDate>\n",
      "            <NumericStartDate>19800601</NumericStartDate>\n",
      "            <NumericEndDate>99990101</NumericEndDate>\n",
      "         </CoverageRange>\n",
      "         <PubFrequencies/>\n",
      "         <ContentModel>CM_DEFAULT</ContentModel>\n",
      "      </PubFrosting>\n",
      "      <GroupFrosting>\n",
      "         <AlphaDate>Aug 8, 1987</AlphaDate>\n",
      "         <StartDate>1987-08-08</StartDate>\n",
      "         <EndDate>1987-08-08</EndDate>\n",
      "         <Locators>\n",
      "            <Locator Type=\"PQPCID\">\n",
      "               <Name>17040171</Name>\n",
      "            </Locator>\n",
      "         </Locators>\n",
      "      </GroupFrosting>\n",
      "\n",
      "      \n",
      "   </DFS>\n",
      "   \n",
      "</RECORD>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_xml(filePath+files[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove html tags from a string\n",
    "def remove_html_tags(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "# Function to remove multiple spaces\n",
    "def remove_spaces(text):\n",
    "    text=re.sub(' +',' ',text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse XML\n",
    "def import_xml(filename):\n",
    "    ID=filename.split('.xml')[0]\n",
    "    file=filePath+filename\n",
    "    \n",
    "    xmlp = et.XMLParser(encoding=\"UTF-8\")\n",
    "    parsed_xml = et.parse(file,parser=xmlp)\n",
    "    root = parsed_xml.getroot()\n",
    "    \n",
    "    try:\n",
    "        for child in root.findall('Obj'):\n",
    "            lang=child.find('Language').find('RawLang').text\n",
    "        if lang=='English':\n",
    "            for child in root.findall('Obj'):\n",
    "                type=child.find('ObjectTypes').find('mstar').text\n",
    "                title=child.find('TitleAtt').find('Title').text\n",
    "                try:\n",
    "                    startdate=child.find('StartDate').text\n",
    "                    enddate=child.find('EndDate').text\n",
    "                except:\n",
    "                    startdate=child.find('NumericDate').text\n",
    "                    enddate=child.find('NumericDate').text\n",
    "\n",
    "            if root.find('TextInfo')!=None:\n",
    "                for node in root.iter('Text'):\n",
    "                    text=node.text\n",
    "                    text=remove_spaces(remove_html_tags(text))\n",
    "                    wordcount=node.get('WordCount')\n",
    "            else:\n",
    "                text=''\n",
    "                wordcount=0\n",
    "\n",
    "            for child in root.findall('DFS'):\n",
    "                pubtitle=child.find('PubFrosting').find('Title').text\n",
    "                sourcetype=child.find('PubFrosting').find('SourceType').text\n",
    "\n",
    "            return ID,title,type,startdate,enddate,text,wordcount,pubtitle,sourcetype\n",
    "        \n",
    "        else:\n",
    "            print(filename, \": non-English article\")\n",
    "    \n",
    "    except:\n",
    "        not_parsed.append(filename)\n",
    "        print('Could not parse:',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2513320605.xml : non-English article\n",
      "2535925933.xml : non-English article\n",
      "2562308056.xml : non-English article\n",
      "2597553077.xml : non-English article\n",
      "2615158963.xml : non-English article\n",
      "2526267996.xml : non-English article\n",
      "2610101974.xml : non-English article\n",
      "2504008199.xml : non-English article\n",
      "2494917725.xml : non-English article\n",
      "2574833128.xml : non-English article\n",
      "2494574343.xml : non-English article\n",
      "2540573529.xml : non-English article\n",
      "2569777007.xml : non-English article\n",
      "2476160416.xml : non-English article\n",
      "2580094400.xml : non-English article\n",
      "2599112888.xml : non-English article\n",
      "2518800245.xml : non-English article\n",
      "2587137023.xml : non-English article\n",
      "2605583882.xml : non-English article\n",
      "2466047613.xml : non-English article\n"
     ]
    }
   ],
   "source": [
    "# Define a thread Pool to process multiple XML files simultaneously\n",
    "# Default set to 3, but may change number of processes depending on instance\n",
    "p = Pool(processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 107.37254595756531 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Apply function with Pool to corpus, may limit number of articles by using split\n",
    "start_time = time.time()\n",
    "\n",
    "not_parsed=[]\n",
    "processed_lists=p.map(import_xml, files)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1040337 entries, 0 to 1040336\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   ID             1040317 non-null  object\n",
      " 1   Title          1040317 non-null  object\n",
      " 2   Type           1040317 non-null  object\n",
      " 3   StartDate      1040317 non-null  object\n",
      " 4   EndDate        1040317 non-null  object\n",
      " 5   Text           1040317 non-null  object\n",
      " 6   TextWordCount  1040317 non-null  object\n",
      " 7   PubTitle       1040317 non-null  object\n",
      " 8   SourceType     1040317 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 71.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Transform processed data into a dataframe\n",
    "df = pd.DataFrame(processed_lists, columns=['ID','Title','Type','StartDate','EndDate','Text',\n",
    "            'TextWordCount','PubTitle', 'SourceType'])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                              Title  Type  \\\n",
      "0   433947392  Federal Officials Seek to Relax Rules for Dump...  News   \n",
      "1   292714709  Connecticut Seacoast Village Says `Enough' to ...  News   \n",
      "2  2227336674  In Battle to Confirm a New Justice, Both Sides...  News   \n",
      "3  1828076074               Toyota, Suzuki agree to explore deal  News   \n",
      "4   421725277   Los Angeles; Limits on Solicitors at LAX Stalled  News   \n",
      "\n",
      "    StartDate     EndDate                                               Text  \\\n",
      "0  2008-10-19  2008-10-19  The Interior Department has advanced a proposa...   \n",
      "1  1988-01-31  1988-01-31  This picturesque river town has adopted rules ...   \n",
      "2  2005-07-03  2005-07-03  WASHINGTON, July 2 - The last time Ralph G. Ne...   \n",
      "3  2016-10-12  2016-10-12  Japanese automakers Toyota and Suzuki said Wed...   \n",
      "4  2002-05-22  2002-05-22  Citing a need for additional study, the city's...   \n",
      "\n",
      "  TextWordCount                               PubTitle  \\\n",
      "0           313                         New York Times   \n",
      "1           407  Los Angeles Times (pre-1997 Fulltext)   \n",
      "2          1686                New York Times (Online)   \n",
      "3           517                     USA Today (Online)   \n",
      "4           215                      Los Angeles Times   \n",
      "\n",
      "                    SourceType  \n",
      "0                   Newspapers  \n",
      "1                   Newspapers  \n",
      "2  Blogs, Podcasts, & Websites  \n",
      "3                   Newspapers  \n",
      "4                   Newspapers  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(not_parsed)>0:\n",
    "    print(len(not_parsed))\n",
    "    print(not_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('/home/ec2-user/SageMaker/New Uncertainty/Jan1985-Dec2021/parsed_xml.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1040337 entries, 0 to 1040336\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   ID             1040317 non-null  object\n",
      " 1   Title          1040317 non-null  object\n",
      " 2   Type           1040317 non-null  object\n",
      " 3   StartDate      1040317 non-null  object\n",
      " 4   EndDate        1040317 non-null  object\n",
      " 5   Text           1040317 non-null  object\n",
      " 6   TextWordCount  1040317 non-null  object\n",
      " 7   PubTitle       1040317 non-null  object\n",
      " 8   SourceType     1040317 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 71.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Jan1985-Dec2021/parsed_xml.pkl')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newspapers                     826064\n",
      "Blogs, Podcasts, & Websites    214253\n",
      "Name: SourceType, dtype: int64\n",
      "News                      1035464\n",
      "Feature                      4051\n",
      "Undefined                     669\n",
      "Commentary                     35\n",
      "General Information            32\n",
      "Article                        29\n",
      "Statistics/Data Report         10\n",
      "Obituary                        8\n",
      "Review                          7\n",
      "Correction/Retraction           5\n",
      "Recipe                          3\n",
      "Interview                       3\n",
      "Editorial                       1\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check article type\n",
    "print(df['SourceType'].value_counts())\n",
    "print(df['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035464 entries, 0 to 1035463\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   ID             1035464 non-null  object\n",
      " 1   Title          1035464 non-null  object\n",
      " 2   Type           1035464 non-null  object\n",
      " 3   StartDate      1035464 non-null  object\n",
      " 4   EndDate        1035464 non-null  object\n",
      " 5   Text           1035464 non-null  object\n",
      " 6   TextWordCount  1035464 non-null  object\n",
      " 7   PubTitle       1035464 non-null  object\n",
      " 8   SourceType     1035464 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 71.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Include only Type==News\n",
    "df=df[df['Type']=='News'].sort_values(['PubTitle','StartDate']).reset_index(drop=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates\n",
    "df['StartDate']=df['StartDate'].astype('datetime64[ns]')\n",
    "df['Year']=df['StartDate'].astype('datetime64[ns]').dt.year\n",
    "df['Month']=df['StartDate'].astype('datetime64[ns]').dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Globe 1987-01-12 2021-12-31\n",
      "Boston Globe (Online) 2002-11-17 2021-12-31\n",
      "Boston Globe (pre-1997 Fulltext) 1985-01-01 1996-12-31\n",
      "Chicago Tribune 1985-08-26 2021-12-31\n",
      "Chicago Tribune (Online) 2017-02-27 2021-12-31\n",
      "Chicago Tribune (pre-1997 Fulltext) 1985-01-01 1996-12-03\n",
      "Los Angeles Times 1988-02-02 2021-12-31\n",
      "Los Angeles Times (Online) 2017-02-26 2021-12-31\n",
      "Los Angeles Times (pre-1997 Fulltext) 1985-01-01 1996-12-03\n",
      "New York Times 1985-01-01 2021-12-31\n",
      "New York Times (Online) 1996-01-01 2021-12-31\n",
      "The Washington Post 1996-12-04 2021-12-31\n",
      "The Washington Post (Online) 2011-05-09 2021-12-31\n",
      "The Washington Post (pre-1997 Fulltext) 1987-01-01 1996-12-03\n",
      "USA TODAY 1997-02-17 2021-12-30\n",
      "USA TODAY (pre-1997 Fulltext) 1987-04-01 1997-02-14\n",
      "USA Today (Online) 2016-05-10 2021-12-30\n",
      "Wall Street Journal 1985-01-02 2021-12-31\n",
      "Wall Street Journal (Online) 2010-01-08 2021-12-31\n"
     ]
    }
   ],
   "source": [
    "# Check start and end dates for each pub title\n",
    "for title in df.sort_values('PubTitle')['PubTitle'].unique():\n",
    "    print(title,min(df[df['PubTitle']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         max(df[df['PubTitle']==title].sort_values('StartDate')['StartDate'].dt.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1013048 entries, 1527 to 1035463\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   ID             1013048 non-null  object        \n",
      " 1   Title          1013048 non-null  object        \n",
      " 2   Type           1013048 non-null  object        \n",
      " 3   StartDate      1013048 non-null  datetime64[ns]\n",
      " 4   EndDate        1013048 non-null  object        \n",
      " 5   Text           1013048 non-null  object        \n",
      " 6   TextWordCount  1013048 non-null  object        \n",
      " 7   PubTitle       1013048 non-null  object        \n",
      " 8   SourceType     1013048 non-null  object        \n",
      " 9   Year           1013048 non-null  int64         \n",
      " 10  Month          1013048 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(8)\n",
      "memory usage: 92.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Clean duplicated news articles due to overlapped databases (referring to ProQuest publication coverage)\n",
    "df=df[~(((df['PubTitle']=='Boston Globe') & (df['StartDate']<datetime.datetime(1997,1,1)))\n",
    "                  | ((df['PubTitle']=='Boston Globe (Online)') & (df['StartDate']<datetime.datetime(2015,9,8))))]\n",
    "df=df[~(((df['PubTitle']=='Chicago Tribune') & (df['StartDate']<datetime.datetime(1996,12,4)))\n",
    "                  | ((df['PubTitle']=='Chicago Tribune (Online)') & (df['StartDate']<datetime.datetime(2017,2,23))))]\n",
    "df=df[~(((df['PubTitle']=='Los Angeles Times') & (df['StartDate']<datetime.datetime(1996,12,4)))\n",
    "                  | ((df['PubTitle']=='Los Angeles Times (Online)') & (df['StartDate']<datetime.datetime(2017,2,21))))]\n",
    "df=df[~((df['PubTitle']=='New York Times (Online)') & (df['StartDate']<datetime.datetime(1996,1,1)))]\n",
    "df=df[~(((df['PubTitle']=='The Washington Post') & (df['StartDate']<datetime.datetime(1996,12,4)))\n",
    "                  | ((df['PubTitle']=='The Washington Post (Online)') & (df['StartDate']<datetime.datetime(2016,5,21))))]\n",
    "df=df[~(((df['PubTitle']=='USA TODAY') & (df['StartDate']<datetime.datetime(1997,2,17)))\n",
    "                  | ((df['PubTitle']=='USA Today (Online)') & (df['StartDate']<datetime.datetime(2012,12,5))))]\n",
    "df=df[~((df['PubTitle']=='Wall Street Journal (Online)') & (df['StartDate']<datetime.datetime(2010,1,8)))]\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate newspaper names\n",
    "df.loc[(df['PubTitle']=='Boston Globe (pre-1997 Fulltext)') | (df['PubTitle']=='Boston Globe') | \n",
    "       (df['PubTitle']=='Boston Globe (Online)'),'Newspaper']='Boston Globe'\n",
    "df.loc[(df['PubTitle']=='Wall Street Journal') | (df['PubTitle']=='Wall Street Journal (Online)'),\n",
    "    'Newspaper']='Wall Street Journal'\n",
    "df.loc[(df['PubTitle']=='USA TODAY (pre-1997 Fulltext)') | (df['PubTitle']=='USA TODAY') | \n",
    "       (df['PubTitle']=='USA Today (Online)'),'Newspaper']='USA Today'\n",
    "df.loc[(df['PubTitle']=='Chicago Tribune (pre-1997 Fulltext)') | (df['PubTitle']=='Chicago Tribune') | \n",
    "       (df['PubTitle']=='Chicago Tribune (Online)'),'Newspaper']='Chicago Tribune'\n",
    "df.loc[(df['PubTitle']=='Los Angeles Times') | (df['PubTitle']=='Los Angeles Times (pre-1997 Fulltext)') | \n",
    "        (df['PubTitle']=='Los Angeles Times (Online)'),'Newspaper']='Los Angeles Times'\n",
    "df.loc[(df['PubTitle']=='New York Times') | (df['PubTitle']=='New York Times (Online)'),'Newspaper']='New York Times'\n",
    "df.loc[(df['PubTitle']=='The Washington Post') | (df['PubTitle']=='The Washington Post (pre-1997 Fulltext)') | \n",
    "       (df['PubTitle']=='The Washington Post (Online)'),'Newspaper']='The Washington Post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(['Newspaper','StartDate','Title']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Globe 1997-01-01 2021-12-31 48235\n",
      "Boston Globe (Online) 2015-09-08 2021-12-31 8727\n",
      "Boston Globe (pre-1997 Fulltext) 1985-01-01 1996-12-31 20396\n",
      "Chicago Tribune 1996-12-04 2021-12-31 52513\n",
      "Chicago Tribune (Online) 2017-02-27 2021-12-31 8679\n",
      "Chicago Tribune (pre-1997 Fulltext) 1985-01-01 1996-12-03 38857\n",
      "Los Angeles Times 1996-12-04 2021-12-31 63124\n",
      "Los Angeles Times (Online) 2017-02-26 2021-12-31 8151\n",
      "Los Angeles Times (pre-1997 Fulltext) 1985-01-01 1996-12-03 59422\n",
      "New York Times 1985-01-01 2021-12-31 123287\n",
      "New York Times (Online) 1996-01-01 2021-12-31 160486\n",
      "The Washington Post 1996-12-04 2021-12-31 70900\n",
      "The Washington Post (Online) 2016-05-21 2021-12-31 18567\n",
      "The Washington Post (pre-1997 Fulltext) 1987-01-01 1996-12-03 31039\n",
      "USA TODAY 1997-02-17 2021-12-30 19558\n",
      "USA TODAY (pre-1997 Fulltext) 1987-04-01 1997-02-14 11304\n",
      "USA Today (Online) 2016-05-10 2021-12-30 10089\n",
      "Wall Street Journal 1985-01-02 2021-12-31 152114\n",
      "Wall Street Journal (Online) 2010-01-08 2021-12-31 107600\n"
     ]
    }
   ],
   "source": [
    "# Article count by pub title\n",
    "for title in df.sort_values('PubTitle')['PubTitle'].unique():\n",
    "    print(title,min(df[df['PubTitle']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         max(df[df['PubTitle']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         len(df[df['PubTitle']==title]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Globe 1985-01-01 2021-12-31 77358\n",
      "Chicago Tribune 1985-01-01 2021-12-31 100049\n",
      "Los Angeles Times 1985-01-01 2021-12-31 130697\n",
      "New York Times 1985-01-01 2021-12-31 283773\n",
      "The Washington Post 1987-01-01 2021-12-31 120506\n",
      "USA Today 1987-04-01 2021-12-30 40951\n",
      "Wall Street Journal 1985-01-02 2021-12-31 259714\n"
     ]
    }
   ],
   "source": [
    "# Article count by newspaper\n",
    "for title in df.sort_values('Newspaper')['Newspaper'].unique():\n",
    "    print(title,min(df[df['Newspaper']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         max(df[df['Newspaper']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         len(df[df['Newspaper']==title]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify and Remove Duplicated Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty full texts: 0\n",
      "Series([], Name: Newspaper, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Full text for certain articles is not available due to copyright restrictions\n",
    "print(\"Number of empty full texts:\",df[df['Text']==\"\"]['ID'].nunique())\n",
    "print(df[df['Text']==\"\"]['Newspaper'].value_counts())\n",
    "# # Examples\n",
    "# print(df[df['Text']==\"\"]['ID'][-10:])\n",
    "# print(df[df['Text']==\"\"]['Title'][-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text preprocessor (lemmatizer)\n",
    "def my_preprocessor(text):\n",
    "    doc=nlp(text)\n",
    "    lemmas=[token.lemma_ for token in doc if not token.is_punct | token.is_space]\n",
    "    text_out=\" \".join(lemmas)\n",
    "    return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013048 1013048\n"
     ]
    }
   ],
   "source": [
    "# Convert ID and text to list\n",
    "id_list=df['ID'].tolist()\n",
    "text_list=df['Text'].tolist()\n",
    "print(len(text_list), len(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state regulator say yesterday -PRON- would crack down on illegal mail order liquor sale to minor after a 19-year old woman work for -PRON- be able to buy beer wine and Scotch on five occasion by phone without be require to prove -PRON- be of drinking age the regulator warn that the internet and toll free phone shopping represent giant loophole in state drinking law say the liquor be purchase from four different firm and deliver by United Parcel Service Airborne Express a Newton package store and a Canton wine merchant the investigator at the Alcohol Beverage Control Commission be shock at how easy -PRON- be to do this say Michael T. Duffy the state 's consumer affair director -PRON- think this practice be very widespread Massachusetts law which even out of state firm must comply with bar the sale of liquor to anyone under 21 and mandate that only licensed company may deliver alcohol to customer Duffy say -PRON- have no idea how much liquor be be sell by phone or over the internet although -PRON- cite a Forbes magazine estimate that the sale which often bypass state wholesaler have cost state about $ 100 million in lose liquor taxis Duffy say the commission would hold hearing on the Newton package store and the Canton wine merchant by the end of March -PRON- say the practice of the other firm be be refer to the state attorney general state official acknowledge that -PRON- may be difficult to prosecute company like UPS and Airborne Express because -PRON- often do not know -PRON- be liquor -PRON- be deliver neither company be license to deliver alcohol in Massachusetts accord to Duffy the 19-year old woman use -PRON- credit card to order six bottle of french wine by phone from Geerlings amp Wade in Canton Duffy say that the bottle be deliver yesterday and that -PRON- be never ask for identification the woman have previously order by phone a 10-pack of beer and a bottle of Johnnie Walker from Liquor by Wire in Chicago three bottle of wine from Ambrosia Direct Wine in Napa California and a case of wine from the American Wine Exchange in Farmington Connecticut not once be -PRON- ask for identification Duffy say Jay Essa president of Geerlings amp Wade which sell wine in 20 state say employee deliver product in Massachusetts and other state be require to check the buyer 's identification and age if something happen different from that -PRON- do not know what happen -PRON- say -PRON- do not believe -PRON- be any easy for a young adult to buy wine through the mail than -PRON- be any other way the bottle of Johnnie Walker order through Liquor by Wire be deliver to the woman by Marty 's Liquors in Newton and leave on the woman 's doorstep Duffy say Marty Siegal owner of the package store say -PRON- know nothing about the incident if -PRON- happen -PRON- say -PRON- violate company policy in June the Boston Globe report that the sale of liquor on the internet be become increasingly common and that -PRON- be easy for minor to obtain liquor a Globe reporter buy a bottle of Stolichnaya vodka via the internet and have -PRON- deliver to a 2-year old in New York City no question be ask about the age of the recipient the catalogue for Liquor by Wire specifically state that minor be forbid by law to send or receive alcoholic beverage the brochure also note that delivery be not allow in Alabama Vermont New Hampshire and Alaska official at Liquor by Wire could not be reach yesterday\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "print(my_preprocessor(text_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess text by list index\n",
    "def preprocess_text(i):\n",
    "    id=id_list[i]\n",
    "    text_out=my_preprocessor(text_list[i])\n",
    "    return id,text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4863.837230682373 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Use multipleprocessing to preprocess all text\n",
    "start_time = time.time()\n",
    "with Pool(8) as p:\n",
    "    text_lemmatized=p.map(preprocess_text, list(range(len(id_list))))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1013048 entries, 0 to 1013047\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   ID              1013048 non-null  object\n",
      " 1   TextLemmatized  1013048 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Transform processed data into a dataframe\n",
    "df_lemmatized = pd.DataFrame(text_lemmatized, columns=['ID','TextLemmatized'])\n",
    "print(df_lemmatized.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1013048 entries, 0 to 1013047\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   ID              1013048 non-null  object        \n",
      " 1   Title           1013048 non-null  object        \n",
      " 2   Type            1013048 non-null  object        \n",
      " 3   StartDate       1013048 non-null  datetime64[ns]\n",
      " 4   EndDate         1013048 non-null  object        \n",
      " 5   Text            1013048 non-null  object        \n",
      " 6   TextWordCount   1013048 non-null  object        \n",
      " 7   PubTitle        1013048 non-null  object        \n",
      " 8   SourceType      1013048 non-null  object        \n",
      " 9   Year            1013048 non-null  float64       \n",
      " 10  Month           1013048 non-null  float64       \n",
      " 11  Newspaper       1013048 non-null  object        \n",
      " 12  TextLemmatized  1013048 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(10)\n",
      "memory usage: 108.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "df=df.merge(df_lemmatized, on='ID', how='left')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated articles: 22786\n"
     ]
    }
   ],
   "source": [
    "# Check duplicates\n",
    "df['GroupNo']=df.groupby('TextLemmatized').cumcount()+1\n",
    "print(\"Number of duplicated articles:\",df[df['GroupNo']>1]['ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 990262 entries, 0 to 990261\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype         \n",
      "---  ------          --------------   -----         \n",
      " 0   TextLemmatized  990262 non-null  object        \n",
      " 1   ID              990262 non-null  object        \n",
      " 2   Title           990262 non-null  object        \n",
      " 3   Type            990262 non-null  object        \n",
      " 4   StartDate       990262 non-null  datetime64[ns]\n",
      " 5   EndDate         990262 non-null  object        \n",
      " 6   Text            990262 non-null  object        \n",
      " 7   TextWordCount   990262 non-null  object        \n",
      " 8   PubTitle        990262 non-null  object        \n",
      " 9   SourceType      990262 non-null  object        \n",
      " 10  Year            990262 non-null  float64       \n",
      " 11  Month           990262 non-null  float64       \n",
      " 12  Newspaper       990262 non-null  object        \n",
      " 13  GroupNo         990262 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(10)\n",
      "memory usage: 105.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Keep the earliest article if duplicated\n",
    "df_nodup=df.groupby('TextLemmatized').nth(0).reset_index()\n",
    "print(df_nodup.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated articles: 0\n",
      "Number of unavailable articles: 0\n"
     ]
    }
   ],
   "source": [
    "df_nodup['GroupNo']=df_nodup.groupby('TextLemmatized').cumcount()+1\n",
    "print(\"Number of duplicated articles:\", df_nodup[df_nodup['GroupNo']>1]['ID'].nunique())\n",
    "print(\"Number of unavailable articles:\",df_nodup[df_nodup['TextLemmatized']==\"\"]['ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dataframes to release memory\n",
    "del df\n",
    "del df_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Globe 1985-01-01 2021-12-31 75946\n",
      "Chicago Tribune 1985-01-01 2021-12-31 99327\n",
      "Los Angeles Times 1985-01-01 2021-12-31 129998\n",
      "New York Times 1985-01-01 2021-12-31 273223\n",
      "The Washington Post 1987-01-01 2021-12-31 117519\n",
      "USA Today 1987-04-01 2021-12-30 40387\n",
      "Wall Street Journal 1985-01-02 2021-12-31 253862\n"
     ]
    }
   ],
   "source": [
    "# Check start and end dates for each newspaper\n",
    "for title in df_nodup.sort_values('Newspaper')['Newspaper'].unique():\n",
    "    print(title,min(df_nodup[df_nodup['Newspaper']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         max(df_nodup[df_nodup['Newspaper']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         len(df_nodup[df_nodup['Newspaper']==title]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Globe 1997-01-01 2021-12-31 47343\n",
      "Boston Globe (Online) 2015-09-08 2021-12-31 8210\n",
      "Boston Globe (pre-1997 Fulltext) 1985-01-01 1996-12-31 20393\n",
      "Chicago Tribune 1996-12-04 2021-12-31 52237\n",
      "Chicago Tribune (Online) 2017-02-27 2021-12-31 8410\n",
      "Chicago Tribune (pre-1997 Fulltext) 1985-01-01 1996-12-03 38680\n",
      "Los Angeles Times 1996-12-04 2021-12-31 62640\n",
      "Los Angeles Times (Online) 2017-02-26 2021-12-31 8030\n",
      "Los Angeles Times (pre-1997 Fulltext) 1985-01-01 1996-12-03 59328\n",
      "New York Times 1985-01-01 2021-12-31 122489\n",
      "New York Times (Online) 1996-01-01 2021-12-31 150734\n",
      "The Washington Post 1996-12-04 2021-12-31 68673\n",
      "The Washington Post (Online) 2016-05-21 2021-12-31 17842\n",
      "The Washington Post (pre-1997 Fulltext) 1987-01-01 1996-12-03 31004\n",
      "USA TODAY 1997-02-17 2021-12-30 19508\n",
      "USA TODAY (pre-1997 Fulltext) 1987-04-01 1997-02-14 11297\n",
      "USA Today (Online) 2016-05-10 2021-12-30 9582\n",
      "Wall Street Journal 1985-01-02 2021-12-31 151874\n",
      "Wall Street Journal (Online) 2010-01-08 2021-12-31 101988\n"
     ]
    }
   ],
   "source": [
    "# Check start and end dates for each pub title\n",
    "for title in df_nodup.sort_values('PubTitle')['PubTitle'].unique():\n",
    "    print(title,min(df_nodup[df_nodup['PubTitle']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         max(df_nodup[df_nodup['PubTitle']==title].sort_values('StartDate')['StartDate'].dt.date),\n",
    "         len(df_nodup[df_nodup['PubTitle']==title]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodup.to_pickle('/home/ec2-user/SageMaker/New Uncertainty/Jan1985-Dec2021/parsed_xml_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
